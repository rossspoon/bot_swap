{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = \"Pilot5\"\n",
    "data_dir = f\"/Users/thenning/Documents/GitHub/neurobubbles/Data/{session}\"\n",
    "order_data = pd.read_csv((glob.glob(f\"{data_dir}/orders*.csv\"))[0])\n",
    "round_data = pd.read_csv((glob.glob(f\"{data_dir}/rounds*.csv\"))[0])\n",
    "payments_data = pd.read_csv((glob.glob(f\"{data_dir}/payment*.csv\"))[0])\n",
    "prescreen_data = pd.read_csv((glob.glob(f\"{data_dir}/prescreen*.csv\"))[0])\n",
    "pagetime_data = pd.read_csv((glob.glob(f\"{data_dir}/PageTimes*.csv\"))[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_price_data(order_data):\n",
    "    sell_orders = []\n",
    "    min_sell_price = []\n",
    "    buy_orders = []\n",
    "    max_buy_price = []\n",
    "    market_price = []\n",
    "    volume = []\n",
    "    for round in np.unique(order_data['round_number']):\n",
    "        df = order_data[order_data['round_number']== round]\n",
    "        sell_orders.append(np.sum(df[df['type'] == 'SELL']['quantity']))\n",
    "        min_sell_price.append(np.min(df[df['type'] == 'SELL']['price']))\n",
    "        buy_orders.append(np.sum(df[df['type'] == 'BUY']['quantity']))\n",
    "        max_buy_price.append(np.max(df[df['type'] == 'BUY']['price']))\n",
    "        market_price.append(np.unique(df['market_price']))\n",
    "        volume.append(np.unique(df['volume']))\n",
    "\n",
    "\n",
    "    #turning into numpy arrays cause its nice\n",
    "    sell_orders_array = np.array(sell_orders)\n",
    "    min_sell_price_array = np.array(min_sell_price)\n",
    "    buy_orders_array = np.array(buy_orders)\n",
    "    max_buy_price_array = np.array(max_buy_price)\n",
    "    market_price_array = np.array(market_price)\n",
    "    volume_array = np.array(volume)\n",
    "    return sell_orders_array, min_sell_price_array, buy_orders_array, max_buy_price_array,market_price_array, volume_array\n",
    "\n",
    "sell_orders_array, min_sell_price_array, buy_orders_array, max_buy_price_array,market_price_array, volume_array = basic_price_data(order_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Adjusted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_round_risk_adjusted(round_data):\n",
    "    risk_adjusted_score=[]\n",
    "    for i in np.unique(round_data['subsession.round_number']):\n",
    "        if i <= 3:\n",
    "            risk_adjusted_score.append(None)\n",
    "        else:\n",
    "            r1 = round_data[round_data['subsession.round_number'] == i]\n",
    "            risk_adjusted_score.append(np.mean(r1[\"player.dose_r\"]))\n",
    "    return risk_adjusted_score\n",
    "risk_adjusted_score = get_round_risk_adjusted(round_data)\n",
    "\n",
    "def get_risk_adj_mv_avg(round_data, m):\n",
    "    risk_adjusted_score = get_round_risk_adjusted(round_data)\n",
    "    mv_avg = []\n",
    "    for idx, score in enumerate(risk_adjusted_score):\n",
    "        if idx < 3: # makes sure not in practice\n",
    "            continue\n",
    "        else:\n",
    "            scores = []\n",
    "            if idx - m < 3: # if moving average would go into practice then cut avg short\n",
    "                if idx - 3 == 0: #fixes 0 case\n",
    "                    scores.append(risk_adjusted_score[idx])\n",
    "                else:\n",
    "                    for i in range(idx - 3):\n",
    "                        scores.append(risk_adjusted_score[idx - i])\n",
    "            else:\n",
    "                for i in range(idx - m):\n",
    "                    scores.append(risk_adjusted_score[idx - i])\n",
    "            mv_avg.append(np.mean(scores))\n",
    "    return mv_avg\n",
    "\n",
    "risk_adjusted_score = get_risk_adj_mv_avg(round_data, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Forecast Error 10-period')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_forecast_data(round_data):\n",
    "    f1mean_forecast=[]\n",
    "    f2mean_forecast=[]\n",
    "    f3mean_forecast=[]\n",
    "    f4mean_forecast=[]\n",
    "    for i in np.unique(round_data['subsession.round_number']):\n",
    "        r1 = round_data[round_data['subsession.round_number'] == i]\n",
    "        f1mean_forecast.append(np.mean(r1['player.f0']))\n",
    "        f2mean_forecast.append(np.mean(r1['player.f1']))\n",
    "        f3mean_forecast.append(np.mean(r1['player.f2']))\n",
    "        f4mean_forecast.append(np.mean(r1['player.f3']))\n",
    "    return [f1mean_forecast, f2mean_forecast, f3mean_forecast, f4mean_forecast]\n",
    "\n",
    "def forecast_error(round_data,market_price_array, t, m):\n",
    "    forecasts = get_forecast_data(round_data)\n",
    "    if m == 0:\n",
    "        forecast_array = forecasts[0]\n",
    "    elif m == 2:\n",
    "        forecast_array = forecasts[1]\n",
    "    elif m == 5:\n",
    "        forecast_array = forecasts[2]\n",
    "    elif m == 10:\n",
    "        forecast_array = forecasts[3]\n",
    "\n",
    "    forecast_error = forecast_array[t-m] - market_price_array[t]\n",
    "    return forecast_error[0]\n",
    "\n",
    "def generate_forecast_error(round_data, market_price_array, m):\n",
    "    forecast_error_array = []\n",
    "    for t, price in enumerate(market_price_array):\n",
    "        if t < m:\n",
    "            error = None\n",
    "        else:\n",
    "            error = forecast_error(round_data, market_price_array, t, m)\n",
    "        forecast_error_array.append(error)\n",
    "    return forecast_error_array\n",
    "\n",
    "m = 10\n",
    "errors = generate_forecast_error(round_data, market_price_array, m)\n",
    "plt.plot(errors[m:])\n",
    "plt.title(f\"Forecast Error {m}-period\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orderbook Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orderbook_pressure_per_round(order_data, t):\n",
    "    round_data = order_data[order_data['round_number']== t]\n",
    "    market_price = np.unique(round_data['market_price'])[0]\n",
    "\n",
    "    buy_d = round_data[round_data['type'] =='BUY']\n",
    "    max_unfilled_bid = np.max(buy_d[buy_d['price'] <market_price]['price'])\n",
    "    bid_quantity = np.sum(buy_d[buy_d['price'] ==max_unfilled_bid]['quantity'])\n",
    "\n",
    "    ask_d = round_data[round_data['type'] =='SELL']\n",
    "    min_unfilled_ask = np.min(ask_d[ask_d['price'] > market_price]['price'])\n",
    "    ask_quantity = np.sum(ask_d[ask_d['price'] ==min_unfilled_ask]['quantity'])\n",
    "\n",
    "    obook_pressure = (max_unfilled_bid * bid_quantity + min_unfilled_ask * ask_quantity)/(bid_quantity+ask_quantity)\n",
    "    return obook_pressure\n",
    "\n",
    "def get_order_book_ressure(order_data ):\n",
    "    order_book_pressure = []\n",
    "    for round in np.unique(order_data['round_number']):\n",
    "        order_book_pressure.append(get_orderbook_pressure_per_round(order_data, round))\n",
    "    return (order_book_pressure)\n",
    "order_book_pressure = get_order_book_ressure(order_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_asset_allocation(round_data):\n",
    "    allocation_list = []\n",
    "    for i in np.unique(round_data['subsession.round_number']):\n",
    "        r1 = round_data[round_data['subsession.round_number'] == i]\n",
    "        cash = np.sum(r1['player.cash'])\n",
    "        shares = np.sum(r1['player.shares'])\n",
    "        if i == 4:\n",
    "            price = 14\n",
    "        else:\n",
    "            price = market_price_array[i-2] # -1 since idx starts at 1, -1 for lag\n",
    "        market_cap = shares * price\n",
    "        allocation = cash.item() / market_cap.item()\n",
    "        allocation_list.append(allocation)\n",
    "    return allocation_list\n",
    "allocation_list = get_asset_allocation(round_data)\n",
    "len(allocation_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round Level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'forecast_array' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m         round_ml_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_allocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(allocation_list[\u001b[38;5;28mround\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m11\u001b[39m]:\n\u001b[0;32m---> 37\u001b[0m     round_ml_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m forecast error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_forecast_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mround_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_price_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m round_ml_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(round_ml_data)\n\u001b[1;32m     39\u001b[0m round_ml_data_df\n",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m, in \u001b[0;36mgenerate_forecast_error\u001b[0;34m(round_data, market_price_array, m)\u001b[0m\n\u001b[1;32m     32\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mround_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_price_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     forecast_error_array\u001b[38;5;241m.\u001b[39mappend(error)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forecast_error_array\n",
      "Cell \u001b[0;32mIn[24], line 25\u001b[0m, in \u001b[0;36mforecast_error\u001b[0;34m(round_data, market_price_array, t, m)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m     23\u001b[0m     forecast_array \u001b[38;5;241m=\u001b[39m forecasts[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m forecast_error \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_array\u001b[49m[t\u001b[38;5;241m-\u001b[39mm] \u001b[38;5;241m-\u001b[39m market_price_array[t]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forecast_error[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'forecast_array' referenced before assignment"
     ]
    }
   ],
   "source": [
    "round_ml_data = {\n",
    "    'price': [],\n",
    "    'volume': [],\n",
    "    'lag_price': [],\n",
    "    'lag_volume': [],\n",
    "    'price_change': [],\n",
    "    'period-1 forecast error': [],\n",
    "    'period-3 forecast error': [],\n",
    "    'period-6 forecast error': [],\n",
    "    'period-11 forecast error': [],\n",
    "    'laged_risk_parameter_mv_avg': [],\n",
    "    'rounds_remaining': [],\n",
    "    'order_book_pressure': [],\n",
    "    'asset_allocation': []\n",
    "}\n",
    "\n",
    "# Populate the lists with values for each round\n",
    "for round in np.unique(order_data['round_number']):\n",
    "    if round > 3:\n",
    "        round_ml_data['price'].append(market_price_array[round-1][0])\n",
    "        round_ml_data['volume'].append(market_price_array[round-1][0])\n",
    "        if round == 4:\n",
    "            round_ml_data['price_change'].append(market_price_array[round-1][0] - 14)\n",
    "            round_ml_data['lag_price'].append(14)\n",
    "            round_ml_data['lag_volume'].append(None)\n",
    "            round_ml_data[f'laged_risk_parameter_mv_avg'].append(None)\n",
    "        else:\n",
    "            round_ml_data['price_change'].append(market_price_array[round-1][0] - market_price_array[round-2][0])\n",
    "            round_ml_data['lag_price'].append(market_price_array[round-2][0])\n",
    "            round_ml_data['lag_volume'].append(volume_array[round-2][0])\n",
    "            round_ml_data[f'laged_risk_parameter_mv_avg'].append(risk_adjusted_score[round - 3 - 2]) # -3 since it doesn't include practice, -1 since round index starts at 1, -1 for lagged\n",
    "        round_ml_data['rounds_remaining'].append(33 - round)\n",
    "        round_ml_data['order_book_pressure'].append(order_book_pressure[round-1])\n",
    "        round_ml_data['asset_allocation'].append(allocation_list[round-1])\n",
    "\n",
    "for m in [1,3,6,11]:\n",
    "    round_ml_data[f'period-{m} forecast error'] = generate_forecast_error(round_data, market_price_array[3:], m)\n",
    "round_ml_data_df = pd.DataFrame.from_dict(round_ml_data)\n",
    "round_ml_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_dataorder_data(order_data, market_price_array, risk_adjusted_score, order_book_pressure, allocation_list):\n",
    "    \n",
    "    round_ml_data = {\n",
    "    'price': [],\n",
    "    'volume': [],\n",
    "    'lag_price': [],\n",
    "    'lag_volume': [],\n",
    "    'price_change': [],\n",
    "    'period-1 forecast error': [],\n",
    "    'period-3 forecast error': [],\n",
    "    'period-6 forecast error': [],\n",
    "    'period-11 forecast error': [],\n",
    "    'laged_risk_parameter_mv_avg': [],\n",
    "    'rounds_remaining': [],\n",
    "    'order_book_pressure': [],\n",
    "    'asset_allocation': []\n",
    "}\n",
    "\n",
    "    # Populate the lists with values for each round\n",
    "    for round in np.unique(order_data['round_number']):\n",
    "        if round > 3:\n",
    "            round_ml_data['price'].append(market_price_array[round-1][0])\n",
    "            round_ml_data['volume'].append(volume_array[round-1][0])\n",
    "            if round == 4:\n",
    "                round_ml_data['price_change'].append(market_price_array[round-1][0] - 14)\n",
    "                round_ml_data['lag_price'].append(14)\n",
    "                round_ml_data['lag_volume'].append(None)\n",
    "                round_ml_data[f'laged_risk_parameter_mv_avg'].append(None)\n",
    "            else:\n",
    "                round_ml_data['price_change'].append(market_price_array[round-1][0] - market_price_array[round-2][0])\n",
    "                round_ml_data['lag_price'].append(market_price_array[round-2][0])\n",
    "                round_ml_data['lag_volume'].append(volume_array[round-2][0])\n",
    "                round_ml_data[f'laged_risk_parameter_mv_avg'].append(risk_adjusted_score[round - 3 - 2]) # -3 since it doesn't include practice, -1 since round index starts at 1, -1 for lagged\n",
    "            round_ml_data['rounds_remaining'].append(33 - round)\n",
    "            round_ml_data['order_book_pressure'].append(order_book_pressure[round-1])\n",
    "            round_ml_data['asset_allocation'].append(allocation_list[round-1])\n",
    "\n",
    "    for m in [1,3,6,11]:\n",
    "        round_ml_data[f'period-{m} forecast error'] = generate_forecast_error(round_data, market_price_array[3:], m)\n",
    "    round_ml_data_df = pd.DataFrame.from_dict(round_ml_data)\n",
    "    return round_ml_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'forecast_array' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m round_ml_data_df \u001b[38;5;241m=\u001b[39m \u001b[43morganize_dataorder_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_price_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrisk_adjusted_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder_book_pressure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallocation_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#round_ml_data_df.to_csv(fr\"/Users/thenning/Documents/GitHub/neurobubbles/Data/Summary_Data/Pilot_5/Panel_Data.csv\")\u001b[39;00m\n\u001b[1;32m      3\u001b[0m round_ml_data_df\n",
      "Cell \u001b[0;32mIn[29], line 39\u001b[0m, in \u001b[0;36morganize_dataorder_data\u001b[0;34m(order_data, market_price_array, risk_adjusted_score, order_book_pressure, allocation_list)\u001b[0m\n\u001b[1;32m     36\u001b[0m         round_ml_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masset_allocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(allocation_list[\u001b[38;5;28mround\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m11\u001b[39m]:\n\u001b[0;32m---> 39\u001b[0m     round_ml_data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m forecast error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_forecast_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mround_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_price_array\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m round_ml_data_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(round_ml_data)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m round_ml_data_df\n",
      "Cell \u001b[0;32mIn[24], line 34\u001b[0m, in \u001b[0;36mgenerate_forecast_error\u001b[0;34m(round_data, market_price_array, m)\u001b[0m\n\u001b[1;32m     32\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mround_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_price_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     forecast_error_array\u001b[38;5;241m.\u001b[39mappend(error)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forecast_error_array\n",
      "Cell \u001b[0;32mIn[24], line 25\u001b[0m, in \u001b[0;36mforecast_error\u001b[0;34m(round_data, market_price_array, t, m)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m     23\u001b[0m     forecast_array \u001b[38;5;241m=\u001b[39m forecasts[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 25\u001b[0m forecast_error \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_array\u001b[49m[t\u001b[38;5;241m-\u001b[39mm] \u001b[38;5;241m-\u001b[39m market_price_array[t]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forecast_error[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'forecast_array' referenced before assignment"
     ]
    }
   ],
   "source": [
    "round_ml_data_df = organize_dataorder_data(order_data, market_price_array, risk_adjusted_score, order_book_pressure, allocation_list)\n",
    "#round_ml_data_df.to_csv(fr\"/Users/thenning/Documents/GitHub/neurobubbles/Data/Summary_Data/Pilot_5/Panel_Data.csv\")\n",
    "round_ml_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "import matplotlib.pyplot as plt \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = round_ml_data_df.drop('price', axis=1), round_ml_data_df[['price']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  2.224172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/xgboost/core.py:160: UserWarning: [10:34:53] WARNING: /Users/runner/work/xgboost/xgboost/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Instantiation \n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                  n_estimators = 10, seed = 123) \n",
    "\n",
    "xgb_r.fit(X_train, y_train) \n",
    "# Predict the model \n",
    "pred = xgb_r.predict(X_test) \n",
    "\n",
    "# RMSE Computation \n",
    "rmse = np.sqrt(MSE(y_test, pred)) \n",
    "print(\"RMSE : % f\" %(rmse)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 190, in fit\n    X, y = self._validate_data(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n    _assert_all_finite(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# create an SVR model with a linear kernel \u001b[39;00m\n\u001b[1;32m      2\u001b[0m svr \u001b[38;5;241m=\u001b[39m SVR(kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 5\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLeaveOneOut\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross Validation Scores: \u001b[39m\u001b[38;5;124m\"\u001b[39m, scores)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage CV MSE: \u001b[39m\u001b[38;5;124m\"\u001b[39m, scores\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:450\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[0;32m--> 450\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m~/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m     )\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n30 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py\", line 190, in fit\n    X, y = self._validate_data(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1263, in check_X_y\n    X = check_array(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 1049, in check_array\n    _assert_all_finite(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 126, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"/Users/thenning/Documents/GitHub/neurobubbles/.venv/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 175, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nSVR does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "# create an SVR model with a linear kernel \n",
    "svr = SVR(kernel='linear') \n",
    "  \n",
    "\n",
    "scores = cross_val_score(svr, X, y, cv = LeaveOneOut(), scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV MSE: \", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>lag_price</th>\n",
       "      <th>lag_volume</th>\n",
       "      <th>price_change</th>\n",
       "      <th>period-1 forecast error</th>\n",
       "      <th>period-3 forecast error</th>\n",
       "      <th>period-6 forecast error</th>\n",
       "      <th>period-11 forecast error</th>\n",
       "      <th>laged_risk_parameter_mv_avg</th>\n",
       "      <th>rounds_remaining</th>\n",
       "      <th>order_book_pressure</th>\n",
       "      <th>asset_allocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>14.375000</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.235294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750691</td>\n",
       "      <td>28</td>\n",
       "      <td>15.645161</td>\n",
       "      <td>1.776667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.352941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>27</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>1.811406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>26</td>\n",
       "      <td>16.857143</td>\n",
       "      <td>1.926997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-1.875000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585289</td>\n",
       "      <td>25</td>\n",
       "      <td>16.206897</td>\n",
       "      <td>1.963170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.722222</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581501</td>\n",
       "      <td>24</td>\n",
       "      <td>16.416667</td>\n",
       "      <td>2.120147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.388889</td>\n",
       "      <td>-3.722222</td>\n",
       "      <td>-2.352941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>23</td>\n",
       "      <td>17.347826</td>\n",
       "      <td>2.249673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-4.111111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.638853</td>\n",
       "      <td>22</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.286489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>-2.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.635611</td>\n",
       "      <td>21</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>2.327091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.722222</td>\n",
       "      <td>-4.388889</td>\n",
       "      <td>-5.055556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649507</td>\n",
       "      <td>20</td>\n",
       "      <td>20.476190</td>\n",
       "      <td>2.371264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.764706</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>-3.888889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668083</td>\n",
       "      <td>19</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.390324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.166667</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>-3.611111</td>\n",
       "      <td>-2.428571</td>\n",
       "      <td>0.681744</td>\n",
       "      <td>18</td>\n",
       "      <td>21.517241</td>\n",
       "      <td>2.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.722222</td>\n",
       "      <td>-6.058824</td>\n",
       "      <td>-5.444444</td>\n",
       "      <td>-3.600000</td>\n",
       "      <td>0.681077</td>\n",
       "      <td>17</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>2.580082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.444444</td>\n",
       "      <td>-8.444444</td>\n",
       "      <td>-8.611111</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>0.682698</td>\n",
       "      <td>16</td>\n",
       "      <td>25.571429</td>\n",
       "      <td>2.608702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8.722222</td>\n",
       "      <td>-8.388889</td>\n",
       "      <td>-10.277778</td>\n",
       "      <td>-10.888889</td>\n",
       "      <td>0.693559</td>\n",
       "      <td>15</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>2.461560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-14.166667</td>\n",
       "      <td>-14.111111</td>\n",
       "      <td>-14.117647</td>\n",
       "      <td>-15.705882</td>\n",
       "      <td>0.705092</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.414306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.777778</td>\n",
       "      <td>-14.888889</td>\n",
       "      <td>-16.500000</td>\n",
       "      <td>-15.833333</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>13</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.163051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.352941</td>\n",
       "      <td>-16.166667</td>\n",
       "      <td>-16.111111</td>\n",
       "      <td>-16.888889</td>\n",
       "      <td>0.706218</td>\n",
       "      <td>12</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>2.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.588235</td>\n",
       "      <td>-17.111111</td>\n",
       "      <td>-15.777778</td>\n",
       "      <td>-17.333333</td>\n",
       "      <td>0.705368</td>\n",
       "      <td>11</td>\n",
       "      <td>37.103448</td>\n",
       "      <td>2.226323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.611111</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>-16.277778</td>\n",
       "      <td>-18.812500</td>\n",
       "      <td>0.703436</td>\n",
       "      <td>10</td>\n",
       "      <td>37.960000</td>\n",
       "      <td>2.301486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>-16.470588</td>\n",
       "      <td>-17.333333</td>\n",
       "      <td>-19.705882</td>\n",
       "      <td>0.715893</td>\n",
       "      <td>9</td>\n",
       "      <td>39.444444</td>\n",
       "      <td>2.379291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.333333</td>\n",
       "      <td>-15.666667</td>\n",
       "      <td>-18.941176</td>\n",
       "      <td>-20.444444</td>\n",
       "      <td>0.719058</td>\n",
       "      <td>8</td>\n",
       "      <td>40.235294</td>\n",
       "      <td>2.398340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.625000</td>\n",
       "      <td>-12.444444</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-22.058824</td>\n",
       "      <td>0.724588</td>\n",
       "      <td>7</td>\n",
       "      <td>42.071429</td>\n",
       "      <td>2.466599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.294118</td>\n",
       "      <td>-13.277778</td>\n",
       "      <td>-19.764706</td>\n",
       "      <td>-22.944444</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>6</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.492729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.611111</td>\n",
       "      <td>-10.812500</td>\n",
       "      <td>-17.833333</td>\n",
       "      <td>-22.111111</td>\n",
       "      <td>0.727271</td>\n",
       "      <td>5</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>2.523265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.666667</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-11.333333</td>\n",
       "      <td>-22.444444</td>\n",
       "      <td>0.725174</td>\n",
       "      <td>4</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>2.671651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.055556</td>\n",
       "      <td>-11.166667</td>\n",
       "      <td>-12.944444</td>\n",
       "      <td>-21.294118</td>\n",
       "      <td>0.727212</td>\n",
       "      <td>3</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>2.827460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-5.882353</td>\n",
       "      <td>-8.750000</td>\n",
       "      <td>-18.941176</td>\n",
       "      <td>0.736399</td>\n",
       "      <td>2</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>2.977728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-8.058824</td>\n",
       "      <td>-17.200000</td>\n",
       "      <td>0.737865</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.220398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.833333</td>\n",
       "      <td>-5.333333</td>\n",
       "      <td>-8.555556</td>\n",
       "      <td>-16.058824</td>\n",
       "      <td>0.742431</td>\n",
       "      <td>0</td>\n",
       "      <td>42.375000</td>\n",
       "      <td>3.390515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  volume  lag_price  lag_volume  price_change  \\\n",
       "0    15.0    15.0       14.0         NaN           1.0   \n",
       "1    16.0    16.0       15.0        16.0           1.0   \n",
       "2    16.0    16.0       16.0         6.0           0.0   \n",
       "3    17.0    17.0       16.0         5.0           1.0   \n",
       "4    17.0    17.0       17.0         8.0           0.0   \n",
       "5    17.0    17.0       17.0        12.0           0.0   \n",
       "6    18.0    18.0       17.0         8.0           1.0   \n",
       "7    19.0    19.0       18.0         3.0           1.0   \n",
       "8    20.0    20.0       19.0         9.0           1.0   \n",
       "9    21.0    21.0       20.0        11.0           1.0   \n",
       "10   21.0    21.0       21.0         8.0           0.0   \n",
       "11   22.0    22.0       21.0         9.0           1.0   \n",
       "12   23.0    23.0       22.0         9.0           1.0   \n",
       "13   26.0    26.0       23.0         4.0           3.0   \n",
       "14   28.0    28.0       26.0         3.0           2.0   \n",
       "15   33.0    33.0       28.0         9.0           5.0   \n",
       "16   35.0    35.0       33.0         2.0           2.0   \n",
       "17   36.0    36.0       35.0         8.0           1.0   \n",
       "18   37.0    37.0       36.0         5.0           1.0   \n",
       "19   38.0    38.0       37.0         3.0           1.0   \n",
       "20   40.0    40.0       38.0        16.0           2.0   \n",
       "21   41.0    41.0       40.0         9.0           1.0   \n",
       "22   43.0    43.0       41.0        14.0           2.0   \n",
       "23   45.0    45.0       43.0         9.0           2.0   \n",
       "24   45.0    45.0       45.0         7.0           0.0   \n",
       "25   45.0    45.0       45.0        10.0           0.0   \n",
       "26   45.0    45.0       45.0         9.0           0.0   \n",
       "27   44.0    44.0       45.0         7.0          -1.0   \n",
       "28   44.0    44.0       44.0         6.0           0.0   \n",
       "29   44.0    44.0       44.0        18.0           0.0   \n",
       "\n",
       "    period-1 forecast error  period-3 forecast error  period-6 forecast error  \\\n",
       "0                       NaN                      NaN                      NaN   \n",
       "1                 -3.235294                      NaN                      NaN   \n",
       "2                 -2.352941                      NaN                      NaN   \n",
       "3                 -2.000000                -2.875000                      NaN   \n",
       "4                 -3.777778                -1.875000                      NaN   \n",
       "5                 -2.722222                -1.166667                      NaN   \n",
       "6                 -3.388889                -3.722222                -2.352941   \n",
       "7                 -3.777778                -4.111111                 0.133333   \n",
       "8                 -3.777778                -2.777778                -2.166667   \n",
       "9                 -5.722222                -4.388889                -5.055556   \n",
       "10                -4.764706                -4.666667                -3.888889   \n",
       "11                -5.166667                -5.666667                -3.611111   \n",
       "12                -5.722222                -6.058824                -5.444444   \n",
       "13                -7.444444                -8.444444                -8.611111   \n",
       "14                -8.722222                -8.388889               -10.277778   \n",
       "15               -14.166667               -14.111111               -14.117647   \n",
       "16               -15.777778               -14.888889               -16.500000   \n",
       "17               -13.352941               -16.166667               -16.111111   \n",
       "18               -13.588235               -17.111111               -15.777778   \n",
       "19               -11.611111               -16.000000               -16.277778   \n",
       "20               -10.222222               -16.470588               -17.333333   \n",
       "21               -10.333333               -15.666667               -18.941176   \n",
       "22                -9.625000               -12.444444               -20.000000   \n",
       "23               -10.294118               -13.277778               -19.764706   \n",
       "24               -12.611111               -10.812500               -17.833333   \n",
       "25                -9.666667                -8.000000               -11.333333   \n",
       "26                -8.055556               -11.166667               -12.944444   \n",
       "27                -6.000000                -5.882353                -8.750000   \n",
       "28                -3.777778                -6.222222                -8.058824   \n",
       "29                -3.833333                -5.333333                -8.555556   \n",
       "\n",
       "    period-11 forecast error  laged_risk_parameter_mv_avg  rounds_remaining  \\\n",
       "0                        NaN                          NaN                29   \n",
       "1                        NaN                     0.750691                28   \n",
       "2                        NaN                     0.663946                27   \n",
       "3                        NaN                     0.547890                26   \n",
       "4                        NaN                     0.585289                25   \n",
       "5                        NaN                     0.581501                24   \n",
       "6                        NaN                     0.604748                23   \n",
       "7                        NaN                     0.638853                22   \n",
       "8                        NaN                     0.635611                21   \n",
       "9                        NaN                     0.649507                20   \n",
       "10                       NaN                     0.668083                19   \n",
       "11                 -2.428571                     0.681744                18   \n",
       "12                 -3.600000                     0.681077                17   \n",
       "13                 -5.666667                     0.682698                16   \n",
       "14                -10.888889                     0.693559                15   \n",
       "15                -15.705882                     0.705092                14   \n",
       "16                -15.833333                     0.706468                13   \n",
       "17                -16.888889                     0.706218                12   \n",
       "18                -17.333333                     0.705368                11   \n",
       "19                -18.812500                     0.703436                10   \n",
       "20                -19.705882                     0.715893                 9   \n",
       "21                -20.444444                     0.719058                 8   \n",
       "22                -22.058824                     0.724588                 7   \n",
       "23                -22.944444                     0.722096                 6   \n",
       "24                -22.111111                     0.727271                 5   \n",
       "25                -22.444444                     0.725174                 4   \n",
       "26                -21.294118                     0.727212                 3   \n",
       "27                -18.941176                     0.736399                 2   \n",
       "28                -17.200000                     0.737865                 1   \n",
       "29                -16.058824                     0.742431                 0   \n",
       "\n",
       "    order_book_pressure  asset_allocation  \n",
       "0             14.375000          1.785714  \n",
       "1             15.645161          1.776667  \n",
       "2             15.600000          1.811406  \n",
       "3             16.857143          1.926997  \n",
       "4             16.206897          1.963170  \n",
       "5             16.416667          2.120147  \n",
       "6             17.347826          2.249673  \n",
       "7             19.166667          2.286489  \n",
       "8             20.555556          2.327091  \n",
       "9             20.476190          2.371264  \n",
       "10            21.000000          2.390324  \n",
       "11            21.517241          2.528889  \n",
       "12            22.571429          2.580082  \n",
       "13            25.571429          2.608702  \n",
       "14            27.500000          2.461560  \n",
       "15                  NaN          2.414306  \n",
       "16            35.000000          2.163051  \n",
       "17            36.333333          2.170000  \n",
       "18            37.103448          2.226323  \n",
       "19            37.960000          2.301486  \n",
       "20            39.444444          2.379291  \n",
       "21            40.235294          2.398340  \n",
       "22            42.071429          2.466599  \n",
       "23            45.333333          2.492729  \n",
       "24            45.200000          2.523265  \n",
       "25            45.454545          2.671651  \n",
       "26            44.750000          2.827460  \n",
       "27            44.500000          2.977728  \n",
       "28                  NaN          3.220398  \n",
       "29            42.375000          3.390515  "
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_ml_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>lag_price</th>\n",
       "      <th>lag_volume</th>\n",
       "      <th>price_change</th>\n",
       "      <th>period-1 forecast error</th>\n",
       "      <th>period-3 forecast error</th>\n",
       "      <th>period-6 forecast error</th>\n",
       "      <th>period-11 forecast error</th>\n",
       "      <th>laged_risk_parameter_mv_avg</th>\n",
       "      <th>rounds_remaining</th>\n",
       "      <th>order_book_pressure</th>\n",
       "      <th>asset_allocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.37931</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.430725</td>\n",
       "      <td>-8.803574</td>\n",
       "      <td>-10.982258</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.685164</td>\n",
       "      <td>29</td>\n",
       "      <td>14.375000</td>\n",
       "      <td>1.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.235294</td>\n",
       "      <td>-8.803574</td>\n",
       "      <td>-10.982258</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.750691</td>\n",
       "      <td>28</td>\n",
       "      <td>15.645161</td>\n",
       "      <td>1.776667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.352941</td>\n",
       "      <td>-8.803574</td>\n",
       "      <td>-10.982258</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.663946</td>\n",
       "      <td>27</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>1.811406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.875000</td>\n",
       "      <td>-10.982258</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.547890</td>\n",
       "      <td>26</td>\n",
       "      <td>16.857143</td>\n",
       "      <td>1.926997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-1.875000</td>\n",
       "      <td>-10.982258</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.585289</td>\n",
       "      <td>25</td>\n",
       "      <td>16.206897</td>\n",
       "      <td>1.963170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.722222</td>\n",
       "      <td>-1.166667</td>\n",
       "      <td>-10.982258</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.581501</td>\n",
       "      <td>24</td>\n",
       "      <td>16.416667</td>\n",
       "      <td>2.120147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.388889</td>\n",
       "      <td>-3.722222</td>\n",
       "      <td>-2.352941</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>23</td>\n",
       "      <td>17.347826</td>\n",
       "      <td>2.249673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-4.111111</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.638853</td>\n",
       "      <td>22</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.286489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>-2.166667</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.635611</td>\n",
       "      <td>21</td>\n",
       "      <td>20.555556</td>\n",
       "      <td>2.327091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.722222</td>\n",
       "      <td>-4.388889</td>\n",
       "      <td>-5.055556</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.649507</td>\n",
       "      <td>20</td>\n",
       "      <td>20.476190</td>\n",
       "      <td>2.371264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.764706</td>\n",
       "      <td>-4.666667</td>\n",
       "      <td>-3.888889</td>\n",
       "      <td>-16.334807</td>\n",
       "      <td>0.668083</td>\n",
       "      <td>19</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.390324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.166667</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>-3.611111</td>\n",
       "      <td>-2.428571</td>\n",
       "      <td>0.681744</td>\n",
       "      <td>18</td>\n",
       "      <td>21.517241</td>\n",
       "      <td>2.528889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.722222</td>\n",
       "      <td>-6.058824</td>\n",
       "      <td>-5.444444</td>\n",
       "      <td>-3.600000</td>\n",
       "      <td>0.681077</td>\n",
       "      <td>17</td>\n",
       "      <td>22.571429</td>\n",
       "      <td>2.580082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-7.444444</td>\n",
       "      <td>-8.444444</td>\n",
       "      <td>-8.611111</td>\n",
       "      <td>-5.666667</td>\n",
       "      <td>0.682698</td>\n",
       "      <td>16</td>\n",
       "      <td>25.571429</td>\n",
       "      <td>2.608702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-8.722222</td>\n",
       "      <td>-8.388889</td>\n",
       "      <td>-10.277778</td>\n",
       "      <td>-10.888889</td>\n",
       "      <td>0.693559</td>\n",
       "      <td>15</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>2.461560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-14.166667</td>\n",
       "      <td>-14.111111</td>\n",
       "      <td>-14.117647</td>\n",
       "      <td>-15.705882</td>\n",
       "      <td>0.705092</td>\n",
       "      <td>14</td>\n",
       "      <td>29.520287</td>\n",
       "      <td>2.414306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-15.777778</td>\n",
       "      <td>-14.888889</td>\n",
       "      <td>-16.500000</td>\n",
       "      <td>-15.833333</td>\n",
       "      <td>0.706468</td>\n",
       "      <td>13</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.163051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.352941</td>\n",
       "      <td>-16.166667</td>\n",
       "      <td>-16.111111</td>\n",
       "      <td>-16.888889</td>\n",
       "      <td>0.706218</td>\n",
       "      <td>12</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>2.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13.588235</td>\n",
       "      <td>-17.111111</td>\n",
       "      <td>-15.777778</td>\n",
       "      <td>-17.333333</td>\n",
       "      <td>0.705368</td>\n",
       "      <td>11</td>\n",
       "      <td>37.103448</td>\n",
       "      <td>2.226323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.611111</td>\n",
       "      <td>-16.000000</td>\n",
       "      <td>-16.277778</td>\n",
       "      <td>-18.812500</td>\n",
       "      <td>0.703436</td>\n",
       "      <td>10</td>\n",
       "      <td>37.960000</td>\n",
       "      <td>2.301486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.222222</td>\n",
       "      <td>-16.470588</td>\n",
       "      <td>-17.333333</td>\n",
       "      <td>-19.705882</td>\n",
       "      <td>0.715893</td>\n",
       "      <td>9</td>\n",
       "      <td>39.444444</td>\n",
       "      <td>2.379291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.333333</td>\n",
       "      <td>-15.666667</td>\n",
       "      <td>-18.941176</td>\n",
       "      <td>-20.444444</td>\n",
       "      <td>0.719058</td>\n",
       "      <td>8</td>\n",
       "      <td>40.235294</td>\n",
       "      <td>2.398340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-9.625000</td>\n",
       "      <td>-12.444444</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>-22.058824</td>\n",
       "      <td>0.724588</td>\n",
       "      <td>7</td>\n",
       "      <td>42.071429</td>\n",
       "      <td>2.466599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-10.294118</td>\n",
       "      <td>-13.277778</td>\n",
       "      <td>-19.764706</td>\n",
       "      <td>-22.944444</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>6</td>\n",
       "      <td>45.333333</td>\n",
       "      <td>2.492729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.611111</td>\n",
       "      <td>-10.812500</td>\n",
       "      <td>-17.833333</td>\n",
       "      <td>-22.111111</td>\n",
       "      <td>0.727271</td>\n",
       "      <td>5</td>\n",
       "      <td>45.200000</td>\n",
       "      <td>2.523265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.666667</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>-11.333333</td>\n",
       "      <td>-22.444444</td>\n",
       "      <td>0.725174</td>\n",
       "      <td>4</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>2.671651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.055556</td>\n",
       "      <td>-11.166667</td>\n",
       "      <td>-12.944444</td>\n",
       "      <td>-21.294118</td>\n",
       "      <td>0.727212</td>\n",
       "      <td>3</td>\n",
       "      <td>44.750000</td>\n",
       "      <td>2.827460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-5.882353</td>\n",
       "      <td>-8.750000</td>\n",
       "      <td>-18.941176</td>\n",
       "      <td>0.736399</td>\n",
       "      <td>2</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>2.977728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.777778</td>\n",
       "      <td>-6.222222</td>\n",
       "      <td>-8.058824</td>\n",
       "      <td>-17.200000</td>\n",
       "      <td>0.737865</td>\n",
       "      <td>1</td>\n",
       "      <td>29.520287</td>\n",
       "      <td>3.220398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>18.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.833333</td>\n",
       "      <td>-5.333333</td>\n",
       "      <td>-8.555556</td>\n",
       "      <td>-16.058824</td>\n",
       "      <td>0.742431</td>\n",
       "      <td>0</td>\n",
       "      <td>42.375000</td>\n",
       "      <td>3.390515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  volume  lag_price  lag_volume  price_change  \\\n",
       "0    15.0    15.0       14.0     8.37931           1.0   \n",
       "1    16.0    16.0       15.0    16.00000           1.0   \n",
       "2    16.0    16.0       16.0     6.00000           0.0   \n",
       "3    17.0    17.0       16.0     5.00000           1.0   \n",
       "4    17.0    17.0       17.0     8.00000           0.0   \n",
       "5    17.0    17.0       17.0    12.00000           0.0   \n",
       "6    18.0    18.0       17.0     8.00000           1.0   \n",
       "7    19.0    19.0       18.0     3.00000           1.0   \n",
       "8    20.0    20.0       19.0     9.00000           1.0   \n",
       "9    21.0    21.0       20.0    11.00000           1.0   \n",
       "10   21.0    21.0       21.0     8.00000           0.0   \n",
       "11   22.0    22.0       21.0     9.00000           1.0   \n",
       "12   23.0    23.0       22.0     9.00000           1.0   \n",
       "13   26.0    26.0       23.0     4.00000           3.0   \n",
       "14   28.0    28.0       26.0     3.00000           2.0   \n",
       "15   33.0    33.0       28.0     9.00000           5.0   \n",
       "16   35.0    35.0       33.0     2.00000           2.0   \n",
       "17   36.0    36.0       35.0     8.00000           1.0   \n",
       "18   37.0    37.0       36.0     5.00000           1.0   \n",
       "19   38.0    38.0       37.0     3.00000           1.0   \n",
       "20   40.0    40.0       38.0    16.00000           2.0   \n",
       "21   41.0    41.0       40.0     9.00000           1.0   \n",
       "22   43.0    43.0       41.0    14.00000           2.0   \n",
       "23   45.0    45.0       43.0     9.00000           2.0   \n",
       "24   45.0    45.0       45.0     7.00000           0.0   \n",
       "25   45.0    45.0       45.0    10.00000           0.0   \n",
       "26   45.0    45.0       45.0     9.00000           0.0   \n",
       "27   44.0    44.0       45.0     7.00000          -1.0   \n",
       "28   44.0    44.0       44.0     6.00000           0.0   \n",
       "29   44.0    44.0       44.0    18.00000           0.0   \n",
       "\n",
       "    period-1 forecast error  period-3 forecast error  period-6 forecast error  \\\n",
       "0                 -7.430725                -8.803574               -10.982258   \n",
       "1                 -3.235294                -8.803574               -10.982258   \n",
       "2                 -2.352941                -8.803574               -10.982258   \n",
       "3                 -2.000000                -2.875000               -10.982258   \n",
       "4                 -3.777778                -1.875000               -10.982258   \n",
       "5                 -2.722222                -1.166667               -10.982258   \n",
       "6                 -3.388889                -3.722222                -2.352941   \n",
       "7                 -3.777778                -4.111111                 0.133333   \n",
       "8                 -3.777778                -2.777778                -2.166667   \n",
       "9                 -5.722222                -4.388889                -5.055556   \n",
       "10                -4.764706                -4.666667                -3.888889   \n",
       "11                -5.166667                -5.666667                -3.611111   \n",
       "12                -5.722222                -6.058824                -5.444444   \n",
       "13                -7.444444                -8.444444                -8.611111   \n",
       "14                -8.722222                -8.388889               -10.277778   \n",
       "15               -14.166667               -14.111111               -14.117647   \n",
       "16               -15.777778               -14.888889               -16.500000   \n",
       "17               -13.352941               -16.166667               -16.111111   \n",
       "18               -13.588235               -17.111111               -15.777778   \n",
       "19               -11.611111               -16.000000               -16.277778   \n",
       "20               -10.222222               -16.470588               -17.333333   \n",
       "21               -10.333333               -15.666667               -18.941176   \n",
       "22                -9.625000               -12.444444               -20.000000   \n",
       "23               -10.294118               -13.277778               -19.764706   \n",
       "24               -12.611111               -10.812500               -17.833333   \n",
       "25                -9.666667                -8.000000               -11.333333   \n",
       "26                -8.055556               -11.166667               -12.944444   \n",
       "27                -6.000000                -5.882353                -8.750000   \n",
       "28                -3.777778                -6.222222                -8.058824   \n",
       "29                -3.833333                -5.333333                -8.555556   \n",
       "\n",
       "    period-11 forecast error  laged_risk_parameter_mv_avg  rounds_remaining  \\\n",
       "0                 -16.334807                     0.685164                29   \n",
       "1                 -16.334807                     0.750691                28   \n",
       "2                 -16.334807                     0.663946                27   \n",
       "3                 -16.334807                     0.547890                26   \n",
       "4                 -16.334807                     0.585289                25   \n",
       "5                 -16.334807                     0.581501                24   \n",
       "6                 -16.334807                     0.604748                23   \n",
       "7                 -16.334807                     0.638853                22   \n",
       "8                 -16.334807                     0.635611                21   \n",
       "9                 -16.334807                     0.649507                20   \n",
       "10                -16.334807                     0.668083                19   \n",
       "11                 -2.428571                     0.681744                18   \n",
       "12                 -3.600000                     0.681077                17   \n",
       "13                 -5.666667                     0.682698                16   \n",
       "14                -10.888889                     0.693559                15   \n",
       "15                -15.705882                     0.705092                14   \n",
       "16                -15.833333                     0.706468                13   \n",
       "17                -16.888889                     0.706218                12   \n",
       "18                -17.333333                     0.705368                11   \n",
       "19                -18.812500                     0.703436                10   \n",
       "20                -19.705882                     0.715893                 9   \n",
       "21                -20.444444                     0.719058                 8   \n",
       "22                -22.058824                     0.724588                 7   \n",
       "23                -22.944444                     0.722096                 6   \n",
       "24                -22.111111                     0.727271                 5   \n",
       "25                -22.444444                     0.725174                 4   \n",
       "26                -21.294118                     0.727212                 3   \n",
       "27                -18.941176                     0.736399                 2   \n",
       "28                -17.200000                     0.737865                 1   \n",
       "29                -16.058824                     0.742431                 0   \n",
       "\n",
       "    order_book_pressure  asset_allocation  \n",
       "0             14.375000          1.785714  \n",
       "1             15.645161          1.776667  \n",
       "2             15.600000          1.811406  \n",
       "3             16.857143          1.926997  \n",
       "4             16.206897          1.963170  \n",
       "5             16.416667          2.120147  \n",
       "6             17.347826          2.249673  \n",
       "7             19.166667          2.286489  \n",
       "8             20.555556          2.327091  \n",
       "9             20.476190          2.371264  \n",
       "10            21.000000          2.390324  \n",
       "11            21.517241          2.528889  \n",
       "12            22.571429          2.580082  \n",
       "13            25.571429          2.608702  \n",
       "14            27.500000          2.461560  \n",
       "15            29.520287          2.414306  \n",
       "16            35.000000          2.163051  \n",
       "17            36.333333          2.170000  \n",
       "18            37.103448          2.226323  \n",
       "19            37.960000          2.301486  \n",
       "20            39.444444          2.379291  \n",
       "21            40.235294          2.398340  \n",
       "22            42.071429          2.466599  \n",
       "23            45.333333          2.492729  \n",
       "24            45.200000          2.523265  \n",
       "25            45.454545          2.671651  \n",
       "26            44.750000          2.827460  \n",
       "27            44.500000          2.977728  \n",
       "28            29.520287          3.220398  \n",
       "29            42.375000          3.390515  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_ml_data_df.fillna(round_ml_data_df.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
